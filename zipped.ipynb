{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tarfile\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def wrangle (path):\n",
    "    \"\"\"\n",
    "    path : file path to the csv file to be wrangled\n",
    "    df: wrangled dataframe which is returned\n",
    "    \"\"\"\n",
    "    # Creating the time's dataframe from which time is picked\n",
    "    dftime = pd.read_csv(path, nrows=2)\n",
    "    k=dftime.columns\n",
    "    datetime = pd.to_datetime(k[1])\n",
    "    t1 = datetime\n",
    "    t2 = t1 + pd.Timedelta(minutes=5)\n",
    "    t3 = t1 + pd.Timedelta(minutes=10)\n",
    "    ts = [t1,t2,t3]\n",
    "\n",
    "    # Creating the real data's dataframe\n",
    "    df = pd.read_csv(path, skiprows=5)\n",
    "    # Splitting column values into three separate columns\n",
    "    \n",
    "    df[['Rx1', 'Rx2', 'Rx3']] = df['gponOltSideOntUtilBulkPmIntervalRxUcastBytes'].str.extract(r'{(\\d+), (\\d+), (\\d+)}')\n",
    "    df[['RxDroped1', 'RxDroped2', 'RxDroped3']] = df['gponOltSideOntUtilBulkPmIntervalRxUcastDropBytes'].str.extract(r'{(\\d+), (\\d+), (\\d+)}')\n",
    "    df[['Tx1', 'Tx2', 'Tx3']] = df['gponOltSideOntUtilBulkPmIntervalTxUcastBytes'].str.extract(r'{(\\d+), (\\d+), (\\d+)}')\n",
    "    df[['TxDroped1', 'TxDroped2', 'TxDroped3']] = df['gponOltSideOntUtilBulkPmIntervalTxUcastDropBytes'].str.extract(r'{(\\d+), (\\d+), (\\d+)}')\n",
    "    df.drop(columns=['gponOltSideOntUtilBulkPmIntervalRxUcastBytes','gponOltSideOntUtilBulkPmIntervalRxUcastDropBytes','gponOltSideOntUtilBulkPmIntervalTxUcastBytes','gponOltSideOntUtilBulkPmIntervalTxUcastDropBytes'],inplace=True)\n",
    "    cols =['Rx1', 'Rx2', 'Rx3','RxDroped1', 'RxDroped2', 'RxDroped3','Tx1', 'Tx2', 'Tx3','TxDroped1', 'TxDroped2', 'TxDroped3']\n",
    "    for col in cols:\n",
    "        df[col].fillna(0,inplace=True)\n",
    "        df[col] = df[col].astype(int)\n",
    "    # Melting similar columns into long dataframes to map them to their coresponding time after concatenation\n",
    "    dfRx=pd.melt(df, id_vars=['Object ID'],value_vars=['Rx1','Rx2','Rx3'],var_name='variableRx',value_name='Rx')\n",
    "    dfRxDroped = pd.melt(df, id_vars=['Object ID'],value_vars=['RxDroped1','RxDroped2','RxDroped3'],var_name='varRxDrop',value_name='RxDrop')\n",
    "    dfTx=pd.melt(df, id_vars=['Object ID'],value_vars=['Tx1','Tx2','Tx3'],var_name='variableTx',value_name='Tx')\n",
    "    dfTxDroped = pd.melt(df, id_vars=['Object ID'],value_vars=['TxDroped1','TxDroped2','TxDroped3'],var_name='varTxDrop',value_name='TxDrop')\n",
    "    # Concatenating the long dataframes into one\n",
    "    df = pd.concat([dfRx,dfRxDroped,dfTx,dfTxDroped],axis=1)\n",
    "    # Droping duplicate columns\n",
    "    df = df.loc[:,~df.columns.duplicated()]\n",
    "\n",
    "    # Converting counters into Mbs\n",
    "    for column in df.columns:\n",
    "        if pd.api.types.is_numeric_dtype(df[column]):\n",
    "            df[column] = (df[column]*8)/(5*60*(10**6))\n",
    "            \n",
    "    # Mapping a timestamp to every values\n",
    "    df.loc[df['variableRx']=='Rx1', 'datetime']=ts[0]\n",
    "    df.loc[df['variableRx']=='Rx2', 'datetime']=ts[1]\n",
    "    df.loc[df['variableRx']=='Rx3', 'datetime']=ts[2]\n",
    "    # Changing the datetime column from string to datetime\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    # Splitting the datetime column into Date and Time columns\n",
    "    df['datetime'] = df['datetime'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    # Droping unrequired columns\n",
    "    df.drop(columns=['variableRx','varRxDrop','variableTx','varTxDrop'],inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "olts = ['10.10.6.12_H','10.10.6.11_H','10.10.6.10_H','10.10.6.8_H','10.10.6.7_H','10.10.6.6_H']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraxting paths for all the zipped folders for all the hubs\n",
    "for olt in olts:\n",
    "    file_pattern =f'C:/Users/llubowa/Downloads/SDC Counters-20230703T092420Z-001/SDC Counters/{olt}*.tar.gz'\n",
    "    # Keeping all the paths into file_paths \n",
    "    file_paths = glob(file_pattern)\n",
    "    dataframes =[]\n",
    "    for path in file_paths:\n",
    "        # Using context manager to extract CSV files in the zipped folder and keeping them in the temp folder\n",
    "        with tarfile.open(path,'r:gz') as tar:\n",
    "            tar.extractall(r\"C:\\Users\\llubowa\\Downloads\\SDC Counters-20230703T092420Z-001\\temp\")\n",
    "        # Path to the desired CSV file in the temp folder\n",
    "        csv_path=r\"C:\\Users\\llubowa\\Downloads\\SDC Counters-20230703T092420Z-001\\temp\\iSAM_ontOltUtilBulkHistoryData.csv\"\n",
    "        # Using the wrangle function to manipulate the data into the desired dataframe format \n",
    "        data = wrangle(csv_path)\n",
    "        # Appending the wrangled dataframe to the dataframes list\n",
    "        dataframes.append(data)\n",
    "    # Conctenating all the datafames from the CSV files of a particular olt into one single dataframe\n",
    "    df = pd.concat(dataframes,ignore_index=True)\n",
    "    location = f'C:/Users/llubowa/Downloads/SDC Counters-20230703T092420Z-001/{olt}.csv'\n",
    "    # Creating a CSV file for the generated dataframe and keeping it into the specified location \n",
    "    df.to_csv(location,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
